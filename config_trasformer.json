[
	{
		"dataset": "data/eurusd_m5_ma14_ws240_f6_set1.h5",
		"models": [
			{
				"module": "core.models",
				"class": "ForexForecastingTransformer",
				"params": {
					"d_model": 32,
					"nhead": 4,
					"num_encoder_layers": 2,
					"dropout": 0.3
				},
				"train": {
					"epochs": 1000,
					"min_epochs": 10,
					"batch_size": 1024,
					"patience": 15,
					"reduce_lr": 5,
					"warmup_lr": 5,
					"lr": 0.0001,
					"max_lr": 0.0006,
					"min_lr": 0.00001
				}
			},
			{
				"module": "core.models",
				"class": "ForexForecastingTransformer",
				"params": {
					"d_model": 64,
					"nhead": 4,
					"num_encoder_layers": 2,
					"dropout": 0.3
				},
				"train": {
					"epochs": 1000,
					"min_epochs": 10,
					"batch_size": 1024,
					"patience": 15,
					"reduce_lr": 5,
					"warmup_lr": 5,
					"lr": 0.0001,
					"max_lr": 0.0006,
					"min_lr": 0.00001
				}
			},
			{
				"module": "core.models",
				"class": "ForexForecastingTransformer",
				"params": {
					"d_model": 32,
					"nhead": 4,
					"num_encoder_layers": 3,
					"dropout": 0.3
				},
				"train": {
					"epochs": 1000,
					"min_epochs": 10,
					"batch_size": 1024,
					"patience": 15,
					"reduce_lr": 5,
					"warmup_lr": 5,
					"lr": 0.0001,
					"max_lr": 0.0006,
					"min_lr": 0.00001
				}
			},
			{
				"module": "core.models",
				"class": "ForexForecastingTransformer",
				"params": {
					"d_model": 64,
					"nhead": 4,
					"num_encoder_layers": 3,
					"dropout": 0.3
				},
				"train": {
					"epochs": 1000,
					"min_epochs": 10,
					"batch_size": 1024,
					"patience": 15,
					"reduce_lr": 5,
					"warmup_lr": 5,
					"lr": 0.0001,
					"max_lr": 0.0006,
					"min_lr": 0.00001
				}
			}
		]
	}
]
